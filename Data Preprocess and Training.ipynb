{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from re import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersect(df1,df2):\n",
    "    loc1 = (df1.columns).isin(df2.columns)\n",
    "    loc1 = np.where(loc1 == True)[0]\n",
    "    df1 = df1.iloc[:,loc1]\n",
    "\n",
    "\n",
    "    loc2 = (df2.columns).isin(df1.columns)\n",
    "    loc2 = np.where(loc2 == True)[0]\n",
    "    df2 = df2.iloc[:,loc2]\n",
    "    return df1, df2\n",
    "\n",
    "def col_addname(df,name):\n",
    "    col = df.columns\n",
    "    col = col.map(lambda x: name + x)\n",
    "    df.columns = col\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取测试集和训练集\n",
    "\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "#将响应变量单独列出\n",
    "train_y = data_train['playtime_forever']\n",
    "del data_train['playtime_forever']\n",
    "\n",
    "myid = 'id'\n",
    "\n",
    "#所有feature\n",
    "#features = data_train.columns.tolist()\n",
    "\n",
    "#所有干扰项feature\n",
    "noisy_features = [myid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#增加游戏上市和购买的年，月作为feature\n",
    "#运行完毕后data_train 和 data_test 将修改\n",
    "\n",
    "data_train['purchase_year'] = data_train['purchase_date'].apply(lambda x: int('20'+split(' |,|-',x)[2]) if isinstance(x,str) else 2017)\n",
    "data_train['purchase_month'] = data_train['purchase_date'].apply(lambda x: split(' |,|-',x)[1] if isinstance(x,str) else 'Jan')\n",
    "data_train['purchase_day'] = data_train['purchase_date'].apply(lambda x: int(split(' |,|-',x)[0]) if isinstance(x,str) else 1)\n",
    "\n",
    "data_test['purchase_year'] = data_test['purchase_date'].apply(lambda x: int(split(' |,|-',x)[3]) if isinstance(x,str) else 2017)\n",
    "data_test['purchase_month'] = data_test['purchase_date'].apply(lambda x: split(' |,|-',x)[0] if isinstance(x,str) else 'Jan')\n",
    "data_test['purchase_day'] = data_test['purchase_date'].apply(lambda x: int(split(' |,|-',x)[1]) if isinstance(x,str) else 1)\n",
    "\n",
    "data_train['release_year'] = data_train['release_date'].apply(lambda x: int(split(' |,|-',x)[3]) if isinstance(x,str) else 2017)\n",
    "data_train['release_month'] = data_train['release_date'].apply(lambda x: split(' |,|-',x)[1] if isinstance(x,str) else 'Jan')\n",
    "data_train['release_day'] = data_train['release_date'].apply(lambda x: int(split(' |,|-',x)[0]) if isinstance(x,str) else 1)\n",
    "\n",
    "data_test['release_year'] = data_test['release_date'].apply(lambda x: int('20'+split('-',x)[2]) if isinstance(x,str) else 2017)\n",
    "data_test['release_month'] = data_test['release_date'].apply(lambda x: split('-',x)[1] if isinstance(x,str) else 'Jan')\n",
    "data_test['release_day'] = data_test['release_date'].apply(lambda x: int(split('-',x)[0]) if isinstance(x,str) else 1)\n",
    "\n",
    "data_train = data_train.replace('Jan',int(1))\n",
    "data_train = data_train.replace('Feb',int(2))\n",
    "data_train = data_train.replace('Mar',int(3))\n",
    "data_train = data_train.replace('Apr',int(4))\n",
    "data_train = data_train.replace('May',int(5))\n",
    "data_train = data_train.replace('Jun',int(6))\n",
    "data_train = data_train.replace('Jul',int(7))\n",
    "data_train = data_train.replace('Aug',int(8))\n",
    "data_train = data_train.replace('Sep',int(9))\n",
    "data_train = data_train.replace('Oct',int(10))\n",
    "data_train = data_train.replace('Nov',int(11))\n",
    "data_train = data_train.replace('Dec',int(12))\n",
    "\n",
    "data_test = data_test.replace('Jan',int(1))\n",
    "data_test = data_test.replace('Feb',int(2))\n",
    "data_test = data_test.replace('Mar',int(3))\n",
    "data_test = data_test.replace('Apr',int(4))\n",
    "data_test = data_test.replace('May',int(5))\n",
    "data_test = data_test.replace('Jun',int(6))\n",
    "data_test = data_test.replace('Jul',int(7))\n",
    "data_test = data_test.replace('Aug',int(8))\n",
    "data_test = data_test.replace('Sep',int(9))\n",
    "data_test = data_test.replace('Oct',int(10))\n",
    "data_test = data_test.replace('Nov',int(11))\n",
    "data_test = data_test.replace('Dec',int(12))\n",
    "\n",
    "data_train['gap_day'] = abs((data_train['purchase_year'] - data_train['release_year']) * 365 + (data_train['purchase_month'] - data_train['release_month'])/12 + data_train['purchase_day'] - data_train['release_day'])\n",
    "data_test['gap_day'] = abs((data_test['purchase_year'] - data_test['release_year']) * 365 + (data_test['purchase_month'] - data_test['release_month'])/12 + data_test['purchase_day'] - data_test['release_day'])\n",
    "data_train['gap_year'] = abs(data_train['purchase_year'] - data_train['release_year'])\n",
    "data_test['gap_year'] = abs(data_test['purchase_year'] - data_test['release_year'])\n",
    "#noisy_features.extend(['purchase_date','release_date','purchase_day','release_day','purchase_month','release_month','purchase_year','release_year'])\n",
    "noisy_features.extend(['purchase_date','release_date','purchase_day','release_day','purchase_month','release_month'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#增加tags，categories和genres的one-hot分类\n",
    "#运行完毕后data_train 和 data_test 将修改\n",
    "\n",
    "data_train_tags = data_train['tags'].str.get_dummies(\",\") \n",
    "data_test_tags = data_test['tags'].str.get_dummies(\",\") \n",
    "data_train_categories = data_train['categories'].str.get_dummies(\",\") \n",
    "data_test_categories = data_test['categories'].str.get_dummies(\",\") \n",
    "data_train_genres = data_train['genres'].str.get_dummies(\",\") \n",
    "data_test_genres = data_test['genres'].str.get_dummies(\",\") \n",
    "\n",
    "data_train_tags, data_test_tags = intersect(data_train_tags, data_test_tags)\n",
    "data_train_categories, data_test_categories = intersect(data_train_categories, data_test_categories)\n",
    "data_train_genres, data_test_genres = intersect(data_train_genres, data_test_genres)\n",
    "\n",
    "data_train_tags = col_addname(data_train_tags,'tags')\n",
    "data_test_tags = col_addname(data_test_tags,'tags')\n",
    "data_train_genres = col_addname(data_train_genres,'genres')\n",
    "data_test_genres = col_addname(data_test_genres,'genres')\n",
    "data_train_categories = col_addname(data_train_categories,'categories')\n",
    "data_test_categories = col_addname(data_test_categories,'categories')\n",
    "\n",
    "data_train_dummy = pd.concat([data_train_tags,data_train_categories,data_train_genres])\n",
    "data_test_dummy = pd.concat([data_test_tags,data_test_categories,data_test_genres])\n",
    "dummy_features = data_train_dummy.columns.tolist()\n",
    "\n",
    "\n",
    "data_train = pd.concat([data_train, data_train_tags, data_train_categories, data_train_genres],axis=1)\n",
    "data_test = pd.concat([data_test, data_test_tags, data_test_categories, data_test_genres],axis=1)\n",
    "\n",
    "noisy_features.extend(['tags','categories','genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#增删好评率相关的feature\n",
    "#运行完毕后data_train 和 data_test 将修改\n",
    "\n",
    "data_train['total_positive_reviews'] = data_train['total_positive_reviews'].fillna(method='ffill')\n",
    "data_train['total_negative_reviews'] = data_train['total_negative_reviews'].fillna(method='ffill')\n",
    "data_train['heat'] = data_train['total_positive_reviews'] + data_train['total_negative_reviews']\n",
    "#data_train['total_reviews'] = data_train['total_positive_reviews'] + data_train['total_negative_reviews']\n",
    "data_train['positive_rate'] = data_train['total_positive_reviews'] / (data_train['total_negative_reviews'] + 1)\n",
    "\n",
    "data_test['total_positive_reviews'] = data_test['total_positive_reviews'].fillna(method='ffill')\n",
    "data_test['total_negative_reviews'] = data_test['total_negative_reviews'].fillna(method='ffill')\n",
    "#data_test['total_reviews'] = data_test['total_positive_reviews'] + data_test['total_negative_reviews']\n",
    "data_test['positive_rate'] = data_test['total_positive_reviews'] / (data_test['total_negative_reviews'] + 1)\n",
    "data_test['heat'] = data_test['total_positive_reviews'] + data_test['total_negative_reviews']\n",
    "\n",
    "#noisy_features.extend(['total_negative_reviews','total_positive_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#对 is_free feature 改造\n",
    "#运行完毕后data_train 和 data_test 将修改\n",
    "\n",
    "data_train['is_free'] = data_train['is_free'].astype(int)\n",
    "data_test['is_free'] = data_test['is_free'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#对 price 改造\n",
    "#运行完毕后data_train 和 data_test 将修改\n",
    "\n",
    "data_train['price'] = data_train['price'].apply(lambda x: 40000 if x > 40000 else x)\n",
    "data_test['price'] = data_test['price'].apply(lambda x: 40000 if x > 40000 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#先对非dummy的feature进行分析\n",
    "\n",
    "features = data_train.columns.tolist()\n",
    "non_dummy_features = [f for f in features if f not in noisy_features and f not in dummy_features]\n",
    "data_train_non_dummy = data_train[non_dummy_features]\n",
    "data_test_non_dummy = data_test[non_dummy_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(357, 266)\n",
      "(90, 266)\n"
     ]
    }
   ],
   "source": [
    "#再对dummy的feature进行分析\n",
    "\n",
    "#features = data_train.columns.tolist()\n",
    "data_train_dummy = data_train[dummy_features]\n",
    "data_test_dummy = data_test[dummy_features]\n",
    "\n",
    "print data_train_dummy.shape\n",
    "print data_test_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mok/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data_train_dummy['playtime_forever'] = train_y#np.log(1+ train_y)\n",
    "#data_train_non_dummy['playtime_forever'] = np.log(1+ train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'categoriesCaptions available', u'categoriesCo-op',\n",
      "       u'categoriesCommentary available',\n",
      "       u'categoriesCross-Platform Multiplayer',\n",
      "       u'categoriesFull controller support', u'categoriesIn-App Purchases',\n",
      "       u'categoriesIncludes Source SDK', u'categoriesIncludes level editor',\n",
      "       u'categoriesLocal Co-op', u'categoriesLocal Multi-Player',\n",
      "       ...\n",
      "       u'tagsVisual Novel', u'tagsWalking Simulator', u'tagsWar',\n",
      "       u'tagsWarhammer 40K', u'tagsWestern', u'tagsWorld War I',\n",
      "       u'tagsWorld War II', u'tagsZombies', u'tagseSports',\n",
      "       u'playtime_forever'],\n",
      "      dtype='object', length=267)\n"
     ]
    }
   ],
   "source": [
    "print data_train_dummy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tagsAtmospheric\n",
       "0    2.524314\n",
       "1    3.660071\n",
       "Name: playtime_forever, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_dummy['playtime_forever'].groupby(data_train_dummy['tagsAtmospheric']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#筛选显著的dummy features\n",
    "def filter_useful_dummy_feature(data_train_dummy,thre):\n",
    "    dummy_useful = [\"\"]\n",
    "\n",
    "    for w in data_train_dummy.columns:\n",
    "        if w == 'playtime_forever':\n",
    "            continue\n",
    "        tmp1 = data_train_dummy['playtime_forever'].groupby(data_train_dummy[w]).mean()[0]\n",
    "        tmp2 = data_train_dummy['playtime_forever'].groupby(data_train_dummy[w]).mean()[1]\n",
    "        Max = np.max([tmp1, tmp2])+1e-3\n",
    "        Min = np.min([tmp1, tmp2])+1e-3 \n",
    "        c = data_train[w].sum()\n",
    "        #print w + ':' + str(Max/Min)\n",
    "        if Max/Min > thre:\n",
    "            dummy_useful.append(w)\n",
    "    del dummy_useful[0]\n",
    "    return dummy_useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#筛选同分布的dummy features\n",
    "\n",
    "def filter_samedis_dummy_features(data_train_dummy, data_test_dummy,thre):\n",
    "    from sklearn import linear_model\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    dummy_samedis = [\"\"]\n",
    "    for w in data_train_dummy.columns:\n",
    "\n",
    "        if w == 'playtime_forever':\n",
    "            continue\n",
    "        l1 = data_train_dummy.shape[0]\n",
    "        l2 = data_test_dummy.shape[0]\n",
    "        train = data_train_dummy[w].values\n",
    "        test = data_test_dummy[w].values\n",
    "        train_one = np.ones((l1,1))\n",
    "        test_zero = np.zeros((l2,1))\n",
    "        train = train.reshape((len(train),1))\n",
    "        test = test.reshape((len(test),1))\n",
    "        X = np.concatenate((train,test),axis=0)\n",
    "        y = np.concatenate((train_one, test_zero),axis=0)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)  #2较好\n",
    "        clf = linear_model.SGDClassifier(random_state=1)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        #print w +':'+ str(accuracy_score(y_pred, y_test))\n",
    "        if accuracy_score(y_pred, y_test)<=thre:\n",
    "            dummy_samedis.append(w)\n",
    "    del dummy_samedis[0]\n",
    "    return dummy_samedis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_useful = filter_useful_dummy_feature(data_train_dummy,1.5)\n",
    "dummy_samedis = filter_samedis_dummy_features(data_train_dummy, data_test_dummy,0.78)\n",
    "dummy_features= [i for i in dummy_samedis if i in dummy_useful]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_features = [i for i in dummy_useful if i in dummy_samedis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "122\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "features_final = dummy_features + non_dummy_features\n",
    "train_x = data_train[features_final]\n",
    "test_x = data_test[features_final]\n",
    "print len(dummy_useful)\n",
    "print len(dummy_samedis)\n",
    "print len(features_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = np.log(train_y + 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=100,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=1300, n_jobs=1, oob_score=False, random_state=3,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.01)\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=100,n_estimators=1300,min_samples_split=3,random_state=3)\n",
    "#regr.fit(X_train, y_train,sample_weight=weight)\n",
    "y = train_y ** 2\n",
    "regr.fit(train_x, y,sample_weight=weight)\n",
    "#y_val = np.exp(y_val) - 1\n",
    "#print accuracy_score(y_test, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_y = regr.predict(test_x)\n",
    "test_y = test_y ** 0.5\n",
    "for i in range(len(test_y)):\n",
    "    if test_y[i] < 13:\n",
    "        test_y[i] = test_y[i] ** 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':range(len(test_y)),'playtime_forever':test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
